{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e01c9cf-48f4-4460-9c95-b782adac953b",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install keras-tuner\n",
    "# !pip install nbconvert\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.applications import VGG16, ResNet50\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Lambda, MaxPooling2D, ZeroPadding2D # convolution layers\n",
    "from keras.layers import Dense, Dropout, Flatten # core layers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.preprocessing import image_dataset_from_directory\n",
    "from keras.optimizers.legacy import Adam, SGD\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import keras_tuner\n",
    "from keras_tuner.tuners import RandomSearch, Hyperband\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dce70d2-859b-4aa7-8ea5-50d242c45ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n",
      "2.13.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 01:17:49.535837: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2024-11-03 01:17:49.535856: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-11-03 01:17:49.535859: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-11-03 01:17:49.535887: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-11-03 01:17:49.535900: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2024-11-03 01:17:49.536322: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-11-03 01:17:49.536333: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device = mps_device)\n",
    "    print(x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n",
    "\n",
    "print(tf.__version__)\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aada1175-0d54-4030-ae22-9701425e473b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 168 images belonging to 3 classes.\n",
      "Found 42 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define constants\n",
    "img_width, img_height = 256, 256\n",
    "batch_size = 21\n",
    "epochs = 30\n",
    "num_classes = 3\n",
    "\n",
    "# Define the directory where your data is stored\n",
    "data_path = '../Desktop/Stuff/Tea Photos/Complete Directory'\n",
    "\n",
    "# Use data augmentation and rescaling\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    validation_split=0.2 # Splitting the data into training and validation sets\n",
    ")\n",
    "\n",
    "# Generate training dataset\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # Specify the subset as training data\n",
    ")\n",
    "\n",
    "# Generate validation dataset\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    data_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Specify the subset as validation data\n",
    ")\n",
    "\n",
    "train_img, train_lables = train_generator.next()\n",
    "validation_img, validation_lables = validation_generator.next()\n",
    "\n",
    "train_lables = train_lables.reshape(-1, num_classes)\n",
    "validation_lables = validation_lables.reshape(-1, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05da944e-6ba9-4ea5-bf07-04520e25b38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 01:17:52.639254: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-11-03 01:17:52.639271: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained VGG16 model without the top layer\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "\n",
    "# Freeze the pre-trained layers so they are not trained during the Weather detection process\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Define the model-building function for Keras Tuner\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(base_model) # output.shape = (8, 8, 512)\n",
    "\n",
    "    # Choose the number of conv layers\n",
    "    filters = hp.Choice('filters', values=[512, 1024])\n",
    "    for i in range(hp.Int('num_conv_layers', min_value=2, max_value=4)):\n",
    "        model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "        model.add(Conv2D(filters=filters, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2)) # output.shape = (4, 4, 512/1024)\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Choose the number of dense layers\n",
    "    for j in range(hp.Int('num_dense_layers', min_value=1, max_value=3)):\n",
    "        model.add(Dense(units=hp.Choice(f'units_{j}', values = [16, 128, 1024]), activation='relu'))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3349011-7b63-4170-8a88-0ab87875283f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_test_2/hyperparameter_tuning_1/tuner0.json\n",
      "Best Number of Convolutional Layers: 2\n",
      "Best Number of Dense Layers: 3\n",
      "Results summary\n",
      "Results in my_test_2/hyperparameter_tuning_1\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 094 summary\n",
      "Hyperparameters:\n",
      "filters: 1024\n",
      "num_conv_layers: 2\n",
      "num_dense_layers: 3\n",
      "units_0: 128\n",
      "learning_rate: 0.01\n",
      "units_1: 16\n",
      "units_2: 16\n",
      "Score: 0.7142857313156128\n",
      "\n",
      "Trial 119 summary\n",
      "Hyperparameters:\n",
      "filters: 512\n",
      "num_conv_layers: 3\n",
      "num_dense_layers: 2\n",
      "units_0: 128\n",
      "learning_rate: 0.001\n",
      "units_1: 128\n",
      "units_2: 1024\n",
      "Score: 0.7142857313156128\n",
      "\n",
      "Trial 167 summary\n",
      "Hyperparameters:\n",
      "filters: 1024\n",
      "num_conv_layers: 2\n",
      "num_dense_layers: 3\n",
      "units_0: 128\n",
      "learning_rate: 0.001\n",
      "units_1: 1024\n",
      "units_2: 16\n",
      "Score: 0.7142857313156128\n",
      "\n",
      "Trial 092 summary\n",
      "Hyperparameters:\n",
      "filters: 512\n",
      "num_conv_layers: 4\n",
      "num_dense_layers: 3\n",
      "units_0: 128\n",
      "learning_rate: 0.001\n",
      "units_1: 128\n",
      "units_2: 128\n",
      "Score: 0.6666666865348816\n",
      "\n",
      "Trial 035 summary\n",
      "Hyperparameters:\n",
      "filters: 512\n",
      "num_conv_layers: 3\n",
      "num_dense_layers: 1\n",
      "units_0: 1024\n",
      "learning_rate: 0.001\n",
      "units_1: 128\n",
      "units_2: 16\n",
      "Score: 0.6666666865348816\n",
      "\n",
      "Trial 069 summary\n",
      "Hyperparameters:\n",
      "filters: 1024\n",
      "num_conv_layers: 3\n",
      "num_dense_layers: 3\n",
      "units_0: 1024\n",
      "learning_rate: 0.001\n",
      "units_1: 128\n",
      "units_2: 16\n",
      "Score: 0.6666666865348816\n",
      "\n",
      "Trial 125 summary\n",
      "Hyperparameters:\n",
      "filters: 512\n",
      "num_conv_layers: 2\n",
      "num_dense_layers: 2\n",
      "units_0: 128\n",
      "learning_rate: 0.001\n",
      "units_1: 128\n",
      "units_2: 128\n",
      "Score: 0.6666666865348816\n",
      "\n",
      "Trial 154 summary\n",
      "Hyperparameters:\n",
      "filters: 512\n",
      "num_conv_layers: 4\n",
      "num_dense_layers: 1\n",
      "units_0: 128\n",
      "learning_rate: 0.001\n",
      "units_1: 1024\n",
      "units_2: 128\n",
      "Score: 0.6666666865348816\n",
      "\n",
      "Trial 073 summary\n",
      "Hyperparameters:\n",
      "filters: 1024\n",
      "num_conv_layers: 2\n",
      "num_dense_layers: 1\n",
      "units_0: 128\n",
      "learning_rate: 0.001\n",
      "units_1: 128\n",
      "units_2: 16\n",
      "Score: 0.6666666865348816\n",
      "\n",
      "Trial 089 summary\n",
      "Hyperparameters:\n",
      "filters: 1024\n",
      "num_conv_layers: 2\n",
      "num_dense_layers: 1\n",
      "units_0: 1024\n",
      "learning_rate: 0.001\n",
      "units_1: 128\n",
      "units_2: 1024\n",
      "Score: 0.6666666865348816\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Keras Tuner Hyperband\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=180,\n",
    "    executions_per_trial=1,\n",
    "    directory='my_test_2',\n",
    "    project_name='hyperparameter_tuning_1'\n",
    ")\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "tuner.search(train_img, train_lables, epochs=epochs, validation_data=(validation_img, validation_lables), batch_size = batch_size)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hyperparameters = tuner.oracle.get_best_trials(1)[0].hyperparameters.values\n",
    "best_num_conv_layers = best_hyperparameters['num_conv_layers']\n",
    "best_num_dense_layers = best_hyperparameters['num_dense_layers']\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(f\"Best Number of Convolutional Layers: {best_num_conv_layers}\")\n",
    "print(f\"Best Number of Dense Layers: {best_num_dense_layers}\")\n",
    "\n",
    "# Build the final model with the best hyperparameters\n",
    "best_trial = tuner.oracle.get_best_trials(1)[0]\n",
    "best_model = tuner.hypermodel.build(best_trial.hyperparameters)\n",
    "# best_model.summary()\n",
    "\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "577a3e10-9393-4dfd-b7ed-55b1a5c9c9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 8, 8, 512)         14714688  \n",
      "                                                                 \n",
      " zero_padding2d (ZeroPaddin  (None, 10, 10, 512)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 8, 8, 1024)        4719616   \n",
      "                                                                 \n",
      " zero_padding2d_1 (ZeroPadd  (None, 10, 10, 1024)      0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 8, 1024)        9438208   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 4, 4, 1024)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               2097280   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                2064      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30972179 (118.15 MB)\n",
      "Trainable params: 16257491 (62.02 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.save('tea_classifier.keras')\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8880c3-5b83-4128-a20c-cbf2647a2458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
